{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[{"file_id":"1xe-JxJRpWyWWoYbueIS7LZ6WsSW2OVjH","timestamp":1711367827351}],"gpuType":"T4","authorship_tag":"ABX9TyO8pdte10CeuNkQfMmKt6VC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"TVPBWnVR3G9Q"},"outputs":[],"source":["import numpy as np\n","from sklearn.metrics import r2_score\n","from pandas_datareader import data as pdr\n","import yfinance as yf\n","yf.pdr_override()\n","from datetime import datetime\n","from sklearn.preprocessing import MinMaxScaler\n","from keras.models import Sequential\n","from keras.layers import Dense, LSTM, Dropout\n","import matplotlib.pyplot as plt\n","plt.style.use(\"fivethirtyeight\")\n","%matplotlib inline"]},{"cell_type":"markdown","source":[],"metadata":{"id":"dqKx1tjfJYoK"}},{"cell_type":"code","source":["import torch\n","\n","import copy\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","from pylab import rcParams\n","import matplotlib.pyplot as plt\n","from matplotlib import rc\n","from sklearn.model_selection import train_test_split\n","\n","from torch import nn, optim\n","\n","import torch.nn.functional as F\n","#from arff2pandas import a2p\n","\n","\n","%matplotlib inline\n","%config InlineBackend.figure_format='retina'\n","\n","sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n","\n","HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n","\n","sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n","\n","rcParams['figure.figsize'] = 12, 8\n","\n","RANDOM_SEED = 42\n","np.random.seed(RANDOM_SEED)\n","torch.manual_seed(RANDOM_SEED)"],"metadata":{"id":"OdzP3HEIIqoH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["s_target = 'GOOG'\n","df = pdr.get_data_yahoo(s_target, start='2014-01-01', end=datetime.now())\n","df.head()"],"metadata":{"id":"pl2Riyya3NMH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.columns"],"metadata":{"id":"SBQsKcLJ35TI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(16,6))\n","plt.title(s_target + ' Close Price History')\n","plt.plot(df['Close'])\n","plt.xlabel('Date', fontsize=14)\n","plt.ylabel('Close Price USD ($)', fontsize=14)\n","plt.show()"],"metadata":{"id":"jVTz4gNz3WGi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Close(終値)のデータ\n","data = df\n","dataset = data.values\n","\n","# データを0〜1の範囲に正規化\n","scaler = MinMaxScaler(feature_range=(0,1))\n","scaled_data = scaler.fit_transform(dataset)\n","scaled_data"],"metadata":{"id":"MxLtIEj24XrI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["scaled_data[0:1]"],"metadata":{"id":"UspQ142H-hsh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 全体の80%をトレーニングデータとして扱う\n","training_data_len = int(np.ceil( len(dataset) * .8 ))"],"metadata":{"id":"84-DCwhI5M7t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# どれくらいの期間をもとに予測するか\n","window_size = 60\n","\n","train_data = scaled_data[0:int(training_data_len), :]"],"metadata":{"id":"F8PBJ1md5RC8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# train_dataをx_trainとy_trainに分ける\n","x_train, y_train = [], []\n","for i in range(window_size, len(train_data)):\n","    x_train.append(train_data[i-window_size:i])\n","    y_train.append(train_data[i, 0])"],"metadata":{"id":"tqFZoZFw5o9A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# numpy arrayに変換\n","x_train, y_train = np.array(x_train), np.array(y_train)"],"metadata":{"id":"3y_40mpq5rji"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data = [torch.tensor(s).float() for s in x_train]"],"metadata":{"id":"FDl7o1LgLP9E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"p94kqLatLZao"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# テストデータを作成\n","test_data = scaled_data[training_data_len - window_size: , :]\n","\n","x_test = []\n","y_test = dataset[training_data_len:, :]\n","for i in range(window_size, len(test_data)):\n","    x_test.append(test_data[i-window_size:i])\n","\n","# numpy arrayに変換\n","x_test = np.array(x_test)"],"metadata":{"id":"qbcciG8rKCw8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_data[0]"],"metadata":{"id":"N4uJsAI6ybf1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_data = [torch.tensor(s).float() for s in x_test]"],"metadata":{"id":"Hh-hkKGcMClK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n_seq, seq_len, n_features = x_train.shape\n","x_train.shape"],"metadata":{"id":"RhszbUMy7Nis"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_test.shape"],"metadata":{"id":"249MnlZzxQlw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Encoder(nn.Module):\n","  def __init__(self, seq_len, n_features, embedding_dim=64):\n","    super(Encoder, self).__init__()\n","    self.seq_len, self.n_features = seq_len, n_features\n","    self.embedding_dim, self.hidden_dim = embedding_dim, 2 * embedding_dim\n","    self.rnn1 =nn.LSTM(\n","      input_size=n_features,\n","      hidden_size=self.hidden_dim,\n","      num_layers=1,\n","      batch_first=True\n","    )\n","    self.rnn2 = nn.LSTM(\n","      input_size=self.hidden_dim,\n","      hidden_size=embedding_dim,\n","      num_layers=1,\n","      batch_first=True\n","    )\n","\n","  def forward(self, x):\n","    x = x.reshape((1, -1, self.n_features))  # バッチサイズを1として、残りの次元を自動的に調整する\n","    x, (_, _) = self.rnn1(x)\n","    x, (hidden_n, _) = self.rnn2(x)\n","    #print('enc:',x[0][-1])\n","\n","\n","    return x"],"metadata":{"id":"SCVyEdbU7PVL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Decoder(nn.Module):\n","    def __init__(self,seq_len,input_dim = 64,n_features = 1):\n","      super(Decoder,self).__init__()\n","\n","      self.seq_len,self.input_dim = seq_len,input_dim\n","      self.hidden_dim,self.n_features = 2*input_dim,n_features\n","\n","      self.rnn1 = nn.LSTM(\n","          input_size = input_dim,\n","          hidden_size = input_dim,\n","          num_layers = 1,\n","          batch_first = True\n","      )\n","\n","      self.rnn2 = nn.LSTM(\n","          input_size = input_dim,\n","          hidden_size = self.hidden_dim,\n","          num_layers = 1,\n","          batch_first = True\n","      )\n","\n","      self.output_layer = nn.Linear(self.hidden_dim,n_features)\n","\n","    def forward(self, x):\n","      #x = x.repeat(self.seq_len, self.n_features)\n","      #print(x.shape)\n","      #print('dec:',x[0][0])\n","      #x = torch.flip(x, dims=[0])\n","      #print('dec_rev:',x[0][0])\n","      #x = x.reshape(-1, self.seq_len, self.input_dim)\n","\n","\n","      x, (hidden, cell) = self.rnn1(x)\n","\n","      x, (hidden, cell) = self.rnn2(x)\n","      #print(len(x[0]))\n","\n","      #x = x.reshape((-1, self.hidden_dim))\n","\n","      #print('decode')\n","      #print(self.output_layer(x).shape)\n","      #print(x.shape)\n","\n","      return self.output_layer(x)\n"],"metadata":{"id":"BSilNrnyIl5w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class RecurrentAutoencoder(nn.Module):\n","  def __init__(self,seq_len,n_features,embedding_dim=64):\n","    super(RecurrentAutoencoder, self).__init__()\n","\n","    self.encoder = Encoder(seq_len,n_features,embedding_dim).to(device)\n","    self.decoder = Decoder(seq_len,embedding_dim,n_features).to(device)\n","\n","  def forward(self,x):\n","    x = self.encoder(x)\n","    #print('z:',x.shape)\n","    x = torch.flip(x, dims=[1])\n","    x = self.decoder(x)\n","    #print('recurrent:',x.shape)\n","\n","    return x"],"metadata":{"id":"mGifzXikIzM5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = RecurrentAutoencoder(seq_len, n_features, 128)\n","model = model.to(device)"],"metadata":{"id":"zE46X8xUI1zy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_model(model,train_dataset,val_dataset,n_epochs):\n","  optimizer = torch.optim.Adam(model.parameters(),lr=0.0001)\n","  criterion = nn.L1Loss(reduction = 'sum').to(device)\n","  history = dict(train = [],val = [])\n","\n","  best_model_wts = copy.deepcopy(model.state_dict())\n","  best_loss = 10000.0\n","\n","  for epoch in range(1,n_epochs+1):\n","    print('training')\n","    model = model.train()\n","\n","    train_losses = []\n","    i=0\n","    j=0\n","\n","    for seq_true in train_dataset:\n","      optimizer.zero_grad()\n","      #print(i)\n","      i += 1\n","\n","      seq_true = seq_true.to(device)\n","      seq_pred = model(seq_true)\n","      #print(len(seq_true[0]))\n","      #print(len(seq_pred[0]))\n","      #print(seq_pred.shape)\n","      loss = criterion(seq_true,torch.flip(seq_pred,dims=[1]))\n","\n","      loss.backward()\n","      optimizer.step()\n","\n","      train_losses.append(loss.item())\n","\n","    #print(train_losses)\n","    val_losses = []\n","    model = model.eval()\n","\n","    with torch.no_grad():\n","      for seq_true in val_dataset:\n","        #print(j)\n","        j += j\n","        seq_true = seq_true.to(device)\n","        seq_pred = model(seq_true)\n","\n","        loss = criterion(seq_true,torch.flip(seq_pred,dims=[1]))\n","        val_losses.append(loss.item())\n","    #print(val_losses)\n","    train_loss = np.mean(train_losses)\n","    val_loss = np.mean(val_losses)\n","\n","    history['train'].append(train_loss)\n","    history['val'].append(val_loss)\n","\n","    if val_loss < best_loss:\n","      best_loss = val_loss\n","      best_model_wts = copy.deepcopy(model.state_dict())\n","\n","    print(f'Epoch {epoch}: train loss {train_loss} val loss {val_loss}')\n","\n","  model.load_state_dict(best_model_wts)\n","\n","  return model.eval(),history"],"metadata":{"id":"7EZy6upxJMfn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model,history = train_model(\n","    model,\n","    train_data,\n","    test_data,\n","    n_epochs = 30\n",")"],"metadata":{"id":"jz8b4lemJPh4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["seq_true=train_data[0]\n","seq_true = seq_true.to(device)\n","seq_pred = model(seq_true)\n","seq_true"],"metadata":{"id":"sYWzmgIxKArl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history"],"metadata":{"id":"FYBwkX3dqm37"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","# 例として3次元の配列を作成\n","array = np.array([[[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]]])\n","print(\"元の配列:\")\n","print(array.shape)\n","\n","# 2番目の次元を反転させる\n","reversed_array = array[:, ::-1, :]\n","print(\"\\n2番目の次元を反転させた配列:\")\n","print(reversed_array)\n"],"metadata":{"id":"i42SfedaJWLe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["a = torch.tensor(range(12))\n","a = a.reshape(1,3,4)\n","a"],"metadata":{"id":"kWlUsqf9dvO6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.flip(a, dims=[1])"],"metadata":{"id":"ZiE4ZSjVv3Sm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"MvkURT7BwFfY"},"execution_count":null,"outputs":[]}]}