{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"TVPBWnVR3G9Q"},"outputs":[],"source":["import numpy as np\n","from sklearn.metrics import r2_score\n","from pandas_datareader import data as pdr\n","import yfinance as yf\n","yf.pdr_override()\n","from datetime import datetime\n","from sklearn.preprocessing import MinMaxScaler\n","from keras.models import Sequential\n","from keras.layers import Dense, LSTM, Dropout\n","import matplotlib.pyplot as plt\n","plt.style.use(\"fivethirtyeight\")\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"dqKx1tjfJYoK"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OdzP3HEIIqoH"},"outputs":[],"source":["import torch\n","\n","import copy\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","from pylab import rcParams\n","import matplotlib.pyplot as plt\n","from matplotlib import rc\n","from sklearn.model_selection import train_test_split\n","\n","from torch import nn, optim\n","\n","import torch.nn.functional as F\n","#from arff2pandas import a2p\n","\n","\n","%matplotlib inline\n","%config InlineBackend.figure_format='retina'\n","\n","sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n","\n","HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n","\n","sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n","\n","rcParams['figure.figsize'] = 12, 8\n","\n","RANDOM_SEED = 42\n","np.random.seed(RANDOM_SEED)\n","torch.manual_seed(RANDOM_SEED)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pl2Riyya3NMH"},"outputs":[],"source":["s_target = 'GOOG'\n","df = pdr.get_data_yahoo(s_target, start='2014-01-01', end=datetime.now())\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SBQsKcLJ35TI"},"outputs":[],"source":["df.columns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jVTz4gNz3WGi"},"outputs":[],"source":["plt.figure(figsize=(16,6))\n","plt.title(s_target + ' Close Price History')\n","plt.plot(df['Close'])\n","plt.xlabel('Date', fontsize=14)\n","plt.ylabel('Close Price USD ($)', fontsize=14)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MxLtIEj24XrI"},"outputs":[],"source":["# Close(終値)のデータ\n","data = df\n","dataset = data.values\n","\n","# データを0〜1の範囲に正規化\n","scaler = MinMaxScaler(feature_range=(0,1))\n","scaled_data = scaler.fit_transform(dataset)\n","scaled_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UspQ142H-hsh"},"outputs":[],"source":["scaled_data[0:1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"84-DCwhI5M7t"},"outputs":[],"source":["# 全体の80%をトレーニングデータとして扱う\n","training_data_len = int(np.ceil( len(dataset) * .8 ))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F8PBJ1md5RC8"},"outputs":[],"source":["# どれくらいの期間をもとに予測するか\n","window_size = 60\n","\n","train_data = scaled_data[0:int(training_data_len), :]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tqFZoZFw5o9A"},"outputs":[],"source":["# train_dataをx_trainとy_trainに分ける\n","x_train, y_train = [], []\n","for i in range(window_size, len(train_data)):\n","    x_train.append(train_data[i-window_size:i])\n","    y_train.append(train_data[i, 0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3y_40mpq5rji"},"outputs":[],"source":["# numpy arrayに変換\n","x_train, y_train = np.array(x_train), np.array(y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FDl7o1LgLP9E"},"outputs":[],"source":["train_data = [torch.tensor(s).float() for s in x_train]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p94kqLatLZao"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qbcciG8rKCw8"},"outputs":[],"source":["# テストデータを作成\n","test_data = scaled_data[training_data_len - window_size: , :]\n","\n","x_test = []\n","y_test = dataset[training_data_len:, :]\n","for i in range(window_size, len(test_data)):\n","    x_test.append(test_data[i-window_size:i])\n","\n","# numpy arrayに変換\n","x_test = np.array(x_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N4uJsAI6ybf1"},"outputs":[],"source":["test_data[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hh-hkKGcMClK"},"outputs":[],"source":["test_data = [torch.tensor(s).float() for s in x_test]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RhszbUMy7Nis"},"outputs":[],"source":["n_seq, seq_len, n_features = x_train.shape\n","x_train.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"249MnlZzxQlw"},"outputs":[],"source":["x_test.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SCVyEdbU7PVL"},"outputs":[],"source":["class Encoder(nn.Module):\n","  def __init__(self, seq_len, n_features, embedding_dim=64):\n","    super(Encoder, self).__init__()\n","    self.seq_len, self.n_features = seq_len, n_features\n","    self.embedding_dim, self.hidden_dim = embedding_dim, 2 * embedding_dim\n","    self.rnn1 = nn.LSTM(\n","      input_size=n_features,\n","      hidden_size=self.hidden_dim,\n","      num_layers=1,\n","      batch_first=True\n","    )\n","    self.rnn2 = nn.LSTM(\n","      input_size=self.hidden_dim,\n","      hidden_size=embedding_dim,\n","      num_layers=1,\n","      batch_first=True\n","    )\n","\n","  def forward(self, x):\n","    x = x.reshape((1, -1, self.n_features))  # バッチサイズを1として、残りの次元を自動的に調整する\n","    x, (_, _) = self.rnn1(x)\n","    x, (hidden_n, _) = self.rnn2(x)\n","\n","    return hidden_n.reshape((-1, self.embedding_dim))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BSilNrnyIl5w"},"outputs":[],"source":["class Decoder(nn.Module):\n","    def __init__(self,seq_len,input_dim = 64,n_features = 1):\n","      super(Decoder,self).__init__()\n","\n","      self.seq_len,self.input_dim = seq_len,input_dim\n","      self.hidden_dim,self.n_features = 2*input_dim,n_features\n","\n","      self.rnn1 = nn.LSTM(\n","          input_size = input_dim,\n","          hidden_size = input_dim,\n","          num_layers = 1,\n","          batch_first = True\n","      )\n","\n","      self.rnn2 = nn.LSTM(\n","          input_size = input_dim,\n","          hidden_size = self.hidden_dim,\n","          num_layers = 1,\n","          batch_first = True\n","      )\n","\n","      self.output_layer = nn.Linear(self.hidden_dim,n_features)\n","\n","    def forward(self, x):\n","      x = x.repeat(self.seq_len, self.n_features)\n","      x = x.reshape(self.n_features, self.seq_len, self.input_dim)\n","\n","      x, (hidden, cell) = self.rnn1(x)\n","      x, (hidden, cell) = self.rnn2(x)\n","      #print(len(x[0]))\n","\n","      #x = x.reshape((-1, self.hidden_dim))\n","\n","      return self.output_layer(x)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mGifzXikIzM5"},"outputs":[],"source":["class RecurrentAutoencoder(nn.Module):\n","  def __init__(self,seq_len,n_features,embedding_dim=64):\n","    super(RecurrentAutoencoder, self).__init__()\n","\n","    self.encoder = Encoder(seq_len,n_features,embedding_dim).to(device)\n","    self.decoder = Decoder(seq_len,embedding_dim,n_features).to(device)\n","\n","  def forward(self,x):\n","    x = self.encoder(x)\n","    x = self.decoder(x)\n","\n","    return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zE46X8xUI1zy"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = RecurrentAutoencoder(seq_len, n_features, 128)\n","model = model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7EZy6upxJMfn"},"outputs":[],"source":["def train_model(model,train_dataset,val_dataset,n_epochs):\n","  optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n","  criterion = nn.L1Loss(reduction = 'sum').to(device)\n","  history = dict(train = [],val = [])\n","\n","  best_model_wts = copy.deepcopy(model.state_dict())\n","  best_loss = 10000.0\n","\n","  for epoch in range(1,n_epochs+1):\n","    print('training')\n","    model = model.train()\n","\n","    train_losses = []\n","    i=0\n","    j=0\n","\n","    for seq_true in train_dataset:\n","      optimizer.zero_grad()\n","      print(i)\n","      i += 1\n","\n","      seq_true = seq_true.to(device)\n","      seq_pred = model(seq_true)\n","      #print(len(seq_true[0]))\n","      #print(len(seq_pred[0]))\n","\n","      loss = criterion(seq_true,seq_pred)\n","\n","      loss.backward()\n","      optimizer.step()\n","\n","      train_losses.append(loss.item())\n","\n","    print(train_losses)\n","    val_losses = []\n","    model = model.eval()\n","\n","    with torch.no_grad():\n","      for seq_true in val_dataset:\n","        print(j)\n","        j += j\n","        seq_true = seq_true.to(device)\n","        seq_pred = model(seq_true)\n","\n","        loss = criterion(seq_true,seq_pred)\n","        val_losses.append(loss.item())\n","    print(val_losses)\n","    train_loss = np.mean(train_losses)\n","    val_loss = np.mean(val_losses)\n","\n","    history['train'].append(train_loss)\n","    history['val'].append(val_loss)\n","\n","    if val_loss < best_loss:\n","      best_loss = val_loss\n","      best_model_wts = copy.deepcopy(model.state_dict())\n","\n","    print(f'Epoch {epoch}: train loss {train_loss} val loss {val_loss}')\n","\n","  model.load_state_dict(best_model_wts)\n","\n","  return model.eval(),history"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jz8b4lemJPh4"},"outputs":[],"source":["model,history = train_model(\n","    model,\n","    train_data,\n","    test_data,\n","    n_epochs = 30\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sYWzmgIxKArl"},"outputs":[],"source":["seq_true=train_data[0]\n","seq_true = seq_true.to(device)\n","seq_pred = model(seq_true)\n","seq_true"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i42SfedaJWLe"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMLAAohwMQSszRPgQ/8abLn","gpuType":"T4","private_outputs":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
