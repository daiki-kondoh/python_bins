{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"_kTCMe6ZANkP"},"outputs":[],"source":["!gdown --id 16MIleqoIr1vYxlGk4GKnGmrsCPuWkkpT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dc6ruiNAARfc"},"outputs":[],"source":["!unzip -qq ECG5000.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p4ppW8qlE9a1"},"outputs":[],"source":["import torch\n","\n","import copy\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","from pylab import rcParams\n","import matplotlib.pyplot as plt\n","from matplotlib import rc\n","from sklearn.model_selection import train_test_split\n","\n","from torch import nn, optim\n","\n","import torch.nn.functional as F\n","#from arff2pandas import a2p\n","\n","\n","%matplotlib inline\n","%config InlineBackend.figure_format='retina'\n","\n","sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n","\n","HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n","\n","sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n","\n","rcParams['figure.figsize'] = 12, 8\n","\n","RANDOM_SEED = 42\n","np.random.seed(RANDOM_SEED)\n","torch.manual_seed(RANDOM_SEED)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ib456rSkFXH9"},"outputs":[],"source":["from scipy.io import arff\n","\n","# TRAINデータの読み込み\n","with open('ECG5000_TRAIN.arff', 'r') as f:\n","    data, meta = arff.loadarff(f)\n","train = pd.DataFrame(data)\n","\n","# TESTデータの読み込み\n","with open('ECG5000_TEST.arff', 'r') as f:\n","    data, meta = arff.loadarff(f)\n","test = pd.DataFrame(data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Aw2W9DxzFj6Q"},"outputs":[],"source":["df = train.append(test)\n","df = df.sample(frac=1.0)\n","df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ooUW0CI3F6jb"},"outputs":[],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"liz2wsdrF-r-"},"outputs":[],"source":["CLASS_NORMAL = \"b'1'\"\n","\n","class_names = ['Normal','R on T','PVC','SP','UB']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UgvRsn31GKCM"},"outputs":[],"source":["new_columns = list(df.columns)\n","new_columns[-1] = 'target'\n","df.columns = new_columns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ebrP4B7OHb4c"},"outputs":[],"source":["df.columns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vzfjBx_VGbLc"},"outputs":[],"source":["df.target.value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VIEFdEc5Gfdh"},"outputs":[],"source":["ax = sns.countplot(df.target)\n","ax.set_xticklabels(class_names);"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tK7mVxn7HQ8c"},"outputs":[],"source":["def plot_time_series_class(data, class_name, ax, n_steps=10):\n","  time_series_df = pd.DataFrame(data)\n","\n","  smooth_path = time_series_df.rolling(n_steps).mean()\n","  path_deviation = 2 * time_series_df.rolling(n_steps).std()\n","\n","  under_line = (smooth_path - path_deviation)[0]\n","  over_line = (smooth_path + path_deviation)[0]\n","\n","  ax.plot(smooth_path, linewidth=2)\n","  ax.fill_between(\n","    path_deviation.index,\n","    under_line,\n","    over_line,\n","    alpha=.125\n","  )\n","  ax.set_title(class_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7jIqy4wLILqg"},"outputs":[],"source":["classes = df.target.unique()\n","\n","fig, axs = plt.subplots(\n","  nrows=len(classes) // 3 + 1,\n","  ncols=3,\n","  sharey=True,\n","  figsize=(14, 8)\n",")\n","\n","for i, cls in enumerate(classes):\n","  ax = axs.flat[i]\n","  data = df[df.target == cls] \\\n","    .drop(labels='target', axis=1) \\\n","    .mean(axis=0) \\\n","    .to_numpy()\n","  plot_time_series_class(data, class_names[i], ax)\n","\n","fig.delaxes(axs.flat[-1])\n","fig.tight_layout();"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mRPzFluPKT5h"},"outputs":[],"source":["CLASS_NORMAL = b'1'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"urMctPOoIPqo"},"outputs":[],"source":["normal_df = df[df.target == b'1'].drop(labels='target', axis=1)\n","normal_df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6RcIzmd2JYPZ"},"outputs":[],"source":["anomaly_df = df[df.target != b'1'].drop(labels='target', axis=1)\n","anomaly_df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y4s0_mzdK5Qe"},"outputs":[],"source":["train_df, val_df = train_test_split(\n","  normal_df,\n","  test_size=0.15,\n","  random_state=RANDOM_SEED\n",")\n","\n","val_df, test_df = train_test_split(\n","  val_df,\n","  test_size=0.33,\n","  random_state=RANDOM_SEED\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7WVth14KLFqI"},"outputs":[],"source":["def create_dataset(df):\n","\n","  sequences = df.astype(np.float32).to_numpy().tolist()\n","\n","  dataset = [torch.tensor(s).unsqueeze(1).float() for s in sequences]\n","\n","  n_seq, seq_len, n_features = torch.stack(dataset).shape\n","\n","  return dataset, seq_len, n_features"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Oqso38H0LSg0"},"outputs":[],"source":["train_dataset, seq_len, n_features = create_dataset(train_df)\n","val_dataset, _, _ = create_dataset(val_df)\n","test_normal_dataset, _, _ = create_dataset(test_df)\n","test_anomaly_dataset, _, _ = create_dataset(anomaly_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mlqa2gRjbaJz"},"outputs":[],"source":["seq_len"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GTvLNLTgLdzB"},"outputs":[],"source":["class Encoder(nn.Module):\n","  def __init__(self,seq_len,n_features,embedding_dim = 64):\n","    super(Encoder,self).__init__()\n","\n","    self.seq_len,self.n_features = seq_len,n_features\n","    self.embedding_dim,self.hidden_dim = embedding_dim,2*embedding_dim\n","\n","    self.rnn1 = nn.LSTM(\n","        input_size = self.n_features,\n","        hidden_size = self.hidden_dim,\n","        num_layers = 1,\n","        batch_first = True\n","    )\n","\n","    self.rnn2 = nn.LSTM(\n","        input_size = self.hidden_dim,\n","        hidden_size = self.embedding_dim,\n","        num_layers = 1,\n","        batch_first = True\n","    )\n","\n","  def forward(self,x):\n","    x = x.reshape(1,self.seq_len,self.n_features)\n","    x,(_,_) = self.rnn1(x)\n","    x,(hidden_n,_) = self.rnn2(x)\n","\n","    return hidden_n.reshape((self.n_features,self.embedding_dim))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j2SulaaWLhdx"},"outputs":[],"source":["class Decoder(nn.Module):\n","  def __init__(self,seq_len,input_dim = 64,n_features = 1):\n","    super(Decoder,self).__init__()\n","\n","    self.seq_len,self.input_dim = seq_len,input_dim\n","    self.hidden_dim,self.n_features = 2*input_dim,n_features\n","\n","    self.rnn1 = nn.LSTM(\n","        input_size = input_dim,\n","        hidden_size = input_dim,\n","        num_layers = 1,\n","        batch_first = True\n","    )\n","\n","    self.rnn2 = nn.LSTM(\n","        input_size = input_dim,\n","        hidden_size = self.hidden_dim,\n","        num_layers = 1,\n","        batch_first = True\n","    )\n","\n","    self.output_layer = nn.Linear(self.hidden_dim,n_features)\n","\n","  def forward(self,x):\n","    x = x.repeat(self.seq_len,self.n_features)\n","    x = x.reshape(self.n_features,self.seq_len,self.input_dim)\n","\n","    x,(hidden_dim,cell_n) = self.rnn1(x)\n","    x,(hidden_dim,cell_n) = self.rnn2(x)\n","\n","    x = x.reshape((self.seq_len,self.hidden_dim))\n","\n","    return self.output_layer(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aQLDfOTUY5aD"},"outputs":[],"source":["class RecurrentAutoencoder(nn.Module):\n","  def __init__(self,seq_len,n_features,embedding_dim=64):\n","    super(RecurrentAutoencoder, self).__init__()\n","\n","    self.encoder = Encoder(seq_len,n_features,embedding_dim).to(device)\n","    self.decoder = Decoder(seq_len,embedding_dim,n_features).to(device)\n","\n","  def forward(self,x):\n","    x = self.encoder(x)\n","    x = self.decoder(x)\n","\n","    return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HeVL5CCGdDKN"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = RecurrentAutoencoder(seq_len, n_features, 128)\n","model = model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WAE13b1adSFC"},"outputs":[],"source":["def train_model(model,train_dataset,val_data_set,n_epochs):\n","  optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n","  criterion = nn.L1Loss(reduction = 'sum').to(device)\n","  history = dict(train = [],val = [])\n","\n","  best_model_wts = copy.deepcopy(model.state_dict())\n","  best_loss = 10000.0\n","\n","  for epoch in range(1,n_epochs+1):\n","    print('training')\n","    model = model.train()\n","\n","    train_losses = []\n","    for seq_true in train_dataset:\n","      optimizer.zero_grad()\n","\n","      seq_true = seq_true.to(device)\n","      seq_pred = model(seq_true)\n","\n","      loss = criterion(seq_true,seq_pred)\n","\n","      loss.backward()\n","      optimizer.step()\n","\n","      train_losses.append(loss.item())\n","\n","    val_losses = []\n","    model = model.eval()\n","    with torch.no_grad():\n","      for seq_true in val_data_set:\n","        seq_true = seq_true.to(device)\n","        seq_pred = model(seq_true)\n","\n","        loss = criterion(seq_true,seq_pred)\n","        val_losses.append(loss.item())\n","\n","    train_loss = np.mean(train_losses)\n","    val_loss = np.mean(val_losses)\n","\n","    history['train'].append(train_loss)\n","    history['val'].append(val_loss)\n","\n","    if val_loss < best_loss:\n","      best_loss = val_loss\n","      best_model_wts = copy.deepcopy(model.state_dict())\n","\n","    print(f'Epoch {epoch}: train loss {train_loss} val loss {val_loss}')\n","\n","  model.load_state_dict(best_model_wts)\n","\n","  return model.eval(),history\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3NuaH9anmnMc"},"outputs":[],"source":["model,history = train_model(\n","    model,\n","    train_dataset,\n","    val_dataset,\n","    n_epochs = 30\n",")"]},{"cell_type":"markdown","metadata":{"id":"mEkMvLx14u-I"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vlrtSZS5m_hb"},"outputs":[],"source":["history"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pppjqNIcqRBC"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMr/KEa81LtyolL3656suBU","gpuType":"T4","private_outputs":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
